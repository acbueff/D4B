{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Deep Learning Assessment: Customer Churn Prediction\n",
       "\n",
       "In this notebook, we'll apply deep learning concepts to predict customer churn - a critical business challenge. You'll learn how neural networks can identify patterns in customer behavior data to predict which customers are likely to leave.\n",
       "\n",
       "## Learning Objectives\n",
       "1. Understand how to structure data for deep learning\n",
       "2. Build and train a neural network using PyTorch\n",
       "3. Evaluate model performance on a business metric\n",
       "4. Complete an assessment that tests your ability to improve model performance\n",
       "\n",
       "## Assessment Criteria\n",
       "To pass this assessment, your model must achieve:\n",
       "- Test accuracy > 85% on the holdout set\n",
       "- F1 score > 0.80 for the churn class\n",
       "\n",
       "These metrics ensure your model is both accurate overall and good at identifying customers likely to churn."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import torch\n",
       "import torch.nn as nn\n",
       "import torch.optim as optim\n",
       "import numpy as np\n",
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
       "\n",
       "# Set random seeds for reproducibility\n",
       "np.random.seed(42)\n",
       "torch.manual_seed(42)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Generate Synthetic Customer Data\n",
       "\n",
       "We'll create a synthetic dataset that mimics real customer behavior data. Features include:\n",
       "- Tenure (months)\n",
       "- Monthly charges\n",
       "- Total charges\n",
       "- Number of support calls\n",
       "- Service usage score"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def generate_customer_data(n_samples=1000):\n",
       "    # Generate features\n",
       "    tenure = np.random.randint(1, 72, n_samples)  # 1-72 months\n",
       "    monthly_charges = np.random.uniform(30, 150, n_samples)  # $30-$150\n",
       "    total_charges = monthly_charges * tenure + np.random.normal(0, 100, n_samples)\n",
       "    support_calls = np.random.poisson(2, n_samples)  # Average 2 calls\n",
       "    usage_score = np.random.uniform(0, 100, n_samples)  # 0-100 usage score\n",
       "    \n",
       "    # Combine features\n",
       "    X = np.column_stack([tenure, monthly_charges, total_charges, support_calls, usage_score])\n",
       "    \n",
       "    # Generate churn labels based on a rule\n",
       "    churn_score = (\n",
       "        -0.1 * tenure +  # Longer tenure = less likely to churn\n",
       "        0.3 * (monthly_charges / 50) +  # Higher charges = more likely to churn\n",
       "        0.2 * (support_calls / 2) +  # More support calls = more likely to churn\n",
       "        -0.4 * (usage_score / 50)  # Higher usage = less likely to churn\n",
       "    )\n",
       "    \n",
       "    # Add some randomness\n",
       "    churn_score += np.random.normal(0, 0.1, n_samples)\n",
       "    \n",
       "    # Convert to binary labels\n",
       "    y = (churn_score > 0).astype(np.int64)\n",
       "    \n",
       "    return X, y\n",
       "\n",
       "# Generate data\n",
       "X, y = generate_customer_data()\n",
       "\n",
       "# Split into train and test sets\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
       "\n",
       "# Scale the features\n",
       "scaler = StandardScaler()\n",
       "X_train_scaled = scaler.fit_transform(X_train)\n",
       "X_test_scaled = scaler.transform(X_test)\n",
       "\n",
       "# Convert to PyTorch tensors\n",
       "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
       "y_train_tensor = torch.FloatTensor(y_train)\n",
       "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
       "y_test_tensor = torch.FloatTensor(y_test)\n",
       "\n",
       "# Print dataset information\n",
       "print(f\"Training set shape: {X_train.shape}\")\n",
       "print(f\"Test set shape: {X_test.shape}\")\n",
       "print(f\"Churn rate in training set: {y_train.mean():.2%}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Visualize the Data\n",
       "\n",
       "Let's examine how different features relate to churn probability. This helps us understand what patterns the neural network might learn."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def plot_feature_relationships():\n",
       "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
       "    axes = axes.ravel()\n",
       "    \n",
       "    feature_names = ['Tenure', 'Monthly Charges', 'Support Calls', 'Usage Score']\n",
       "    feature_indices = [0, 1, 3, 4]  # Skip total charges as it's derived from tenure\n",
       "    \n",
       "    for i, (name, idx) in enumerate(zip(feature_names, feature_indices)):\n",
       "        churned = X_train[y_train == 1, idx]\n",
       "        stayed = X_train[y_train == 0, idx]\n",
       "        \n",
       "        axes[i].hist([stayed, churned], bins=20, label=['Stayed', 'Churned'], alpha=0.6)\n",
       "        axes[i].set_title(f'{name} Distribution by Churn Status')\n",
       "        axes[i].set_xlabel(name)\n",
       "        axes[i].set_ylabel('Count')\n",
       "        axes[i].legend()\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "\n",
       "plot_feature_relationships()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Define the Neural Network\n",
       "\n",
       "We'll create a simple neural network with:\n",
       "- Input layer (5 features)\n",
       "- Two hidden layers\n",
       "- Output layer (1 neuron for binary classification)\n",
       "\n",
       "This architecture should be able to capture non-linear relationships in the data."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "class ChurnPredictor(nn.Module):\n",
       "    def __init__(self, input_size=5):\n",
       "        super(ChurnPredictor, self).__init__()\n",
       "        self.layer1 = nn.Linear(input_size, 16)\n",
       "        self.layer2 = nn.Linear(16, 8)\n",
       "        self.layer3 = nn.Linear(8, 1)\n",
       "        self.relu = nn.ReLU()\n",
       "        self.sigmoid = nn.Sigmoid()\n",
       "        \n",
       "    def forward(self, x):\n",
       "        x = self.relu(self.layer1(x))\n",
       "        x = self.relu(self.layer2(x))\n",
       "        x = self.sigmoid(self.layer3(x))\n",
       "        return x\n",
       "\n",
       "# Initialize the model\n",
       "model = ChurnPredictor()\n",
       "criterion = nn.BCELoss()\n",
       "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
       "\n",
       "print(\"Model architecture:\")\n",
       "print(model)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Train the Model\n",
       "\n",
       "We'll train the model for several epochs and monitor both training loss and validation metrics."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def train_model(model, X_train, y_train, X_test, y_test, epochs=100):\n",
       "    train_losses = []\n",
       "    test_metrics = []\n",
       "    \n",
       "    for epoch in range(epochs):\n",
       "        # Training\n",
       "        model.train()\n",
       "        optimizer.zero_grad()\n",
       "        outputs = model(X_train)\n",
       "        loss = criterion(outputs, y_train.view(-1, 1))\n",
       "        loss.backward()\n",
       "        optimizer.step()\n",
       "        train_losses.append(loss.item())\n",
       "        \n",
       "        # Evaluation\n",
       "        if (epoch + 1) % 10 == 0:\n",
       "            model.eval()\n",
       "            with torch.no_grad():\n",
       "                test_outputs = model(X_test)\n",
       "                test_preds = (test_outputs >= 0.5).float()\n",
       "                accuracy = accuracy_score(y_test, test_preds)\n",
       "                f1 = f1_score(y_test, test_preds)\n",
       "                test_metrics.append((epoch, accuracy, f1))\n",
       "                print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, '\n",
       "                      f'Test Accuracy: {accuracy:.4f}, F1: {f1:.4f}')\n",
       "    \n",
       "    return train_losses, test_metrics\n",
       "\n",
       "# Train the model\n",
       "train_losses, test_metrics = train_model(model, X_train_tensor, y_train_tensor, \n",
       "                                        X_test_tensor, y_test_tensor)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Visualize Training Progress"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def plot_training_progress(train_losses, test_metrics):\n",
       "    epochs, accuracies, f1_scores = zip(*test_metrics)\n",
       "    \n",
       "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
       "    \n",
       "    # Plot training loss\n",
       "    ax1.plot(train_losses)\n",
       "    ax1.set_title('Training Loss')\n",
       "    ax1.set_xlabel('Epoch')\n",
       "    ax1.set_ylabel('Loss')\n",
       "    \n",
       "    # Plot test metrics\n",
       "    ax2.plot(epochs, accuracies, label='Accuracy')\n",
       "    ax2.plot(epochs, f1_scores, label='F1 Score')\n",
       "    ax2.set_title('Test Metrics')\n",
       "    ax2.set_xlabel('Epoch')\n",
       "    ax2.set_ylabel('Score')\n",
       "    ax2.legend()\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "\n",
       "plot_training_progress(train_losses, test_metrics)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Final Model Evaluation"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def evaluate_model(model, X_test, y_test):\n",
       "    model.eval()\n",
       "    with torch.no_grad():\n",
       "        test_outputs = model(X_test)\n",
       "        test_preds = (test_outputs >= 0.5).float()\n",
       "        \n",
       "        accuracy = accuracy_score(y_test, test_preds)\n",
       "        f1 = f1_score(y_test, test_preds)\n",
       "        \n",
       "        print(\"\\nFinal Model Performance:\")\n",
       "        print(f\"Accuracy: {accuracy:.4f}\")\n",
       "        print(f\"F1 Score: {f1:.4f}\")\n",
       "        print(\"\\nDetailed Classification Report:\")\n",
       "        print(classification_report(y_test, test_preds))\n",
       "        \n",
       "        # Check if model passes assessment criteria\n",
       "        passes_accuracy = accuracy > 0.85\n",
       "        passes_f1 = f1 > 0.80\n",
       "        \n",
       "        print(\"\\nAssessment Results:\")\n",
       "        print(f\"Accuracy > 85%: {'✓' if passes_accuracy else '✗'}\")\n",
       "        print(f\"F1 Score > 0.80: {'✓' if passes_f1 else '✗'}\")\n",
       "        print(f\"Overall: {'PASS' if (passes_accuracy and passes_f1) else 'FAIL'}\")\n",
       "        \n",
       "        return passes_accuracy and passes_f1\n",
       "\n",
       "passed = evaluate_model(model, X_test_tensor, y_test_tensor)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Your Assessment Task\n",
       "\n",
       "If your model didn't pass both criteria (accuracy > 85% and F1 > 0.80), modify the model architecture or training process to achieve passing scores. You can:\n",
       "\n",
       "1. Add more layers or neurons\n",
       "2. Adjust the learning rate\n",
       "3. Train for more epochs\n",
       "4. Add dropout for regularization\n",
       "5. Try different optimizers\n",
       "\n",
       "Use the code cell below to implement your improvements:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Your improved model here\n",
       "class ImprovedChurnPredictor(nn.Module):\n",
       "    def __init__(self, input_size=5):\n",
       "        super(ImprovedChurnPredictor, self).__init__()\n",
       "        # TODO: Implement your improved architecture\n",
       "        pass\n",
       "    \n",
       "    def forward(self, x):\n",
       "        # TODO: Implement forward pass\n",
       "        pass\n",
       "\n",
       "# Uncomment and modify these lines to train your improved model\n",
       "# improved_model = ImprovedChurnPredictor()\n",
       "# criterion = nn.BCELoss()\n",
       "# optimizer = optim.Adam(improved_model.parameters(), lr=0.01)\n",
       "# train_losses, test_metrics = train_model(improved_model, X_train_tensor, y_train_tensor, \n",
       "#                                         X_test_tensor, y_test_tensor, epochs=100)\n",
       "# plot_training_progress(train_losses, test_metrics)\n",
       "# passed = evaluate_model(improved_model, X_test_tensor, y_test_tensor)"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "llms",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }