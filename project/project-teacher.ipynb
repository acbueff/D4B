{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# AI for Business: Yelp Business Insights Project (Student Version)\n",
       "\n",
       "**Course:** AI for Business\n",
       "**Audience:** Business Professionals\n",
       "\n",
       "**Project Goal:** This project provides hands-on experience applying fundamental AI techniques (NLP, Deep Learning, Reinforcement Learning) to real-world business scenarios using the Yelp Open Dataset. You will build simple models to extract insights from customer reviews, predict business ratings, and simulate a recommendation system.\n",
       "\n",
       "**Business Context:** Businesses across industries leverage AI to understand customers, optimize operations, and drive growth. Yelp data, rich with customer opinions and business details, offers a practical playground to explore how AI can generate valuable business insights – from managing brand reputation by analyzing review sentiment to predicting factors that influence success.\n",
       "\n",
       "**Instructions:** Read through the markdown explanations. Complete the code sections marked with `# TODO:` or containing `...`. Run each cell sequentially to execute the project steps."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Setup: Downloading the Data\n",
       "\n",
       "First, we need to download the Yelp Open Dataset. This dataset contains millions of reviews, business attributes, and user information. \n",
       "\n",
       "*(Note: The dataset is large. The download and extraction might take some time depending on your internet connection. You only need to run the next cell once.)*"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "tags": [
        "student_solution"
       ]
      },
      "outputs": [],
      "source": [
       "# Download and extract the Yelp dataset (run this cell only once)\n",
       "# Note: This command might differ slightly depending on your operating system or environment.\n",
       "# It downloads a compressed file and then extracts the JSON files.\n",
       "\n",
       "# If the commands below cause errors, you might need to download and extract the file manually\n",
       "# from the Yelp Dataset Challenge website and place the JSON files in the same directory\n",
       "# as this notebook.\n",
       "\n",
       "# !wget -O yelp_dataset.tar.gz \"https://s3.amazonaws.com/yelp-dataset/yelp_dataset_challenge_academic_dataset.tar.gz\"\n",
       "# !tar -xzf yelp_dataset.tar.gz\n",
       "\n",
       "print(\"Dataset download/extraction cell (commented out). Ensure JSON files are present.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Data Loading and Initial Exploration\n",
       "\n",
       "We'll load a *sample* of the Yelp reviews to keep processing times manageable for this exercise. In a real business application, you'd typically work with much larger datasets, often requiring more powerful computing resources or cloud platforms.\n",
       "\n",
       "**Business Implication:** Data preparation is a critical first step. The quality and quantity of data directly impact the performance and reliability of any AI model. Businesses must invest in collecting, cleaning, and managing their data effectively."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import json\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns # For potentially nicer visualizations\n",
       "\n",
       "# --- Configuration ---\n",
       "SAMPLE_SIZE = 10000 # Number of reviews to load for this exercise\n",
       "REVIEW_FILE = 'yelp_academic_dataset_review.json' # Assumes the file is in the same directory\n",
       "# ---------------------\n",
       "\n",
       "# Load a sample from review.json \n",
       "reviews_data = []\n",
       "try:\n",
       "    with open(REVIEW_FILE, 'r', encoding='utf-8') as f:\n",
       "        for i, line in enumerate(f):\n",
       "            if i >= SAMPLE_SIZE:\n",
       "                break\n",
       "            reviews_data.append(json.loads(line))\n",
       "except FileNotFoundError:\n",
       "    print(f\"Error: {REVIEW_FILE} not found. Make sure the dataset was downloaded and extracted correctly, and the file is in the same directory as this notebook.\")\n",
       "    # Optionally, add code here to stop execution or handle the error\n",
       "    reviews_data = [] # Ensure reviews_data is empty if file not found\n",
       "\n",
       "if reviews_data: # Proceed only if data was loaded\n",
       "    df_reviews = pd.DataFrame(reviews_data)\n",
       "    print(f\"Successfully loaded {len(df_reviews)} reviews.\")\n",
       "    print(\"First 5 rows of the review data:\")\n",
       "    print(df_reviews.head())\n",
       "    \n",
       "    print(\"\\nBasic information about the data:\")\n",
       "    df_reviews.info()\n",
       "else:\n",
       "    print(\"Skipping further analysis as review data could not be loaded.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Challenge 1: NLP – Sentiment Analysis of Yelp Reviews\n",
       "\n",
       "**Business Context:** Imagine you're the marketing manager for a national restaurant chain. Manually reading thousands of online reviews on Yelp, Google, and social media is impossible. Sentiment analysis automates the process of understanding customer opinions – identifying whether reviews are positive, negative, or neutral. This is similar to how companies like Coca-Cola or Starbucks monitor brand perception and campaign effectiveness in real-time.\n",
       "\n",
       "**Goal:** Build a simple Natural Language Processing (NLP) model to classify Yelp reviews as either positive or negative based on the text content. We'll simplify by labeling reviews with 4 or 5 stars as 'positive' (1) and reviews with 1, 2, or 3 stars as 'negative' (0).\n",
       "\n",
       "**Pass Criterion:** The model must achieve at least **70% accuracy** on a held-out validation set. Accuracy measures how often the model correctly predicts the sentiment (positive/negative) compared to our defined labels (based on star ratings).\n",
       "\n",
       "**Business Implication of Accuracy:** An accuracy of 70% means that for every 100 reviews, the model correctly identifies the sentiment for 70 of them. While not perfect, this can still provide valuable insights at scale. Higher accuracy (e.g., 85-95%) would give a business more confidence in automatically flagging urgent negative feedback or identifying key positive themes. The required accuracy depends on the business application – detecting critical safety issues might require higher accuracy than general trend analysis."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# --- Imports for Challenge 1 ---\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # Added TfidfVectorizer for optional extension\n",
       "from sklearn.naive_bayes import MultinomialNB # Using a simpler baseline model for illustration\n",
       "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
       "from sklearn.pipeline import Pipeline\n",
       "import torch\n",
       "import torch.nn as nn\n",
       "import torch.optim as optim\n",
       "# --------------------------------\n",
       "\n",
       "# Ensure df_reviews was loaded successfully in the previous cell\n",
       "if 'df_reviews' in locals() and not df_reviews.empty: \n",
       "    \n",
       "    # --- Preprocessing ---\n",
       "    # 1. Labeling: Create the 'sentiment' column.\n",
       "    # Reviews with 4 or 5 stars are positive (1), others are negative (0).\n",
       "    df_reviews['sentiment'] = (df_reviews['stars'] >= 4).astype(int)\n",
       "    \n",
       "    # Get the text data (features) and the sentiment labels (target)\n",
       "    texts = df_reviews['text'].tolist()\n",
       "    labels = df_reviews['sentiment'].tolist()\n",
       "    \n",
       "    # 2. Data Split: Separate data for training and testing the model.\n",
       "    #    Use train_test_split from scikit-learn.\n",
       "    #    - Use 'texts' and 'labels' as input data.\n",
       "    #    - Set test_size to 0.2 (20% for validation).\n",
       "    #    - Set random_state to 42 for reproducible results.\n",
       "    #    - Use stratify=labels to ensure train/validation sets have similar proportions of positive/negative reviews.\n",
       "    X_train, X_val, y_train, y_val = ... # TODO: Call train_test_split\n",
       "    \n",
       "    print(f\"Training set size: {len(X_train)} reviews\")\n",
       "    print(f\"Validation set size: {len(X_val)} reviews\")\n",
       "\n",
       "    # --- Model Option 1: Simple Scikit-learn Pipeline (Good Baseline) ---\n",
       "    print(\"\\n--- Training a Simple Naive Bayes Classifier ---\")\n",
       "    # Create a pipeline: This chains steps together. \n",
       "    # Step 1: Vectorizer - Converts text into numerical features (word counts).\n",
       "    # Step 2: Classifier - Learns to predict sentiment from the numerical features.\n",
       "    pipeline_nb = Pipeline([\n",
       "        # TODO: Add CountVectorizer step.\n",
       "        # Name: 'vectorizer'\n",
       "        # Tool: CountVectorizer(stop_words='english', max_features=5000)\n",
       "        # ('step_name', Tool(...)), \n",
       "        ('vectorizer', ...), \n",
       "        \n",
       "        # TODO: Add MultinomialNB classifier step.\n",
       "        # Name: 'classifier'\n",
       "        # Tool: MultinomialNB()\n",
       "        ('classifier', ...)\n",
       "    ])\n",
       "\n",
       "    # Train the model: Call the .fit() method on the pipeline\n",
       "    # Use the training data (X_train, y_train)\n",
       "    # TODO: Fit the pipeline\n",
       "    # pipeline_nb. ... \n",
       "\n",
       "    # Evaluate on validation set: Use the trained pipeline to make predictions\n",
       "    # Call the .predict() method on the pipeline using the validation texts (X_val)\n",
       "    y_pred_nb = ... # TODO: Make predictions\n",
       "    \n",
       "    # Calculate accuracy: Use accuracy_score from scikit-learn\n",
       "    # Compare the true validation labels (y_val) with the predictions (y_pred_nb)\n",
       "    accuracy_nb = ... # TODO: Calculate accuracy\n",
       "    \n",
       "    print(f\"Naive Bayes Validation Accuracy: {accuracy_nb:.4f}\")\n",
       "    print(classification_report(y_val, y_pred_nb, target_names=['Negative', 'Positive']))\n",
       "    \n",
       "    # --- Model Option 2: PyTorch MLP (More Complex Model) ---\n",
       "    print(\"\\n--- Training a PyTorch MLP Classifier ---\")\n",
       "    # Create a bag-of-words representation (separate from the pipeline for PyTorch)\n",
       "    # We need to convert text to numbers before feeding to PyTorch\n",
       "    vectorizer_pt = CountVectorizer(stop_words='english', max_features=5000)\n",
       "    # Fit on training data and transform it\n",
       "    X_train_bow = vectorizer_pt.fit_transform(X_train).toarray()\n",
       "    # Only transform validation data (use the vocabulary learned from training)\n",
       "    X_val_bow = vectorizer_pt.transform(X_val).toarray() \n",
       "\n",
       "    # Define the sentiment analysis model using PyTorch\n",
       "    class SentimentMLP(nn.Module):\n",
       "        def __init__(self, input_dim):\n",
       "            super(SentimentMLP, self).__init__()\n",
       "            # Define the layers of the neural network\n",
       "            self.net = nn.Sequential(\n",
       "                # TODO: Add a Linear layer (input features -> 64 features)\n",
       "                # Use nn.Linear(in_features=..., out_features=...)\n",
       "                ..., \n",
       "                \n",
       "                # TODO: Add a ReLU activation function\n",
       "                # Use nn.ReLU()\n",
       "                ...,\n",
       "                \n",
       "                # TODO: Add a Linear layer (64 features -> 1 output feature)\n",
       "                # The output predicts the sentiment (needs sigmoid activation later)\n",
       "                ...\n",
       "            )\n",
       "        def forward(self, x):\n",
       "            # Define how data flows through the network\n",
       "            # Apply sigmoid to the output of the network to get a probability (0 to 1)\n",
       "            return torch.sigmoid(self.net(x))\n",
       "\n",
       "    # --- Setup for PyTorch Training ---\n",
       "    input_dim = X_train_bow.shape[1] # Number of features from CountVectorizer\n",
       "    \n",
       "    # TODO: Instantiate the model\n",
       "    # model_pt = SentimentMLP(input_dim=...)\n",
       "    model_pt = ... \n",
       "\n",
       "    # TODO: Define the loss function\n",
       "    # Use Binary Cross Entropy Loss for binary classification\n",
       "    # criterion = nn.BCELoss()\n",
       "    criterion = ...\n",
       "    \n",
       "    # TODO: Define the optimizer\n",
       "    # Use Adam optimizer to update model weights\n",
       "    # Pass model parameters (model_pt.parameters()) and learning rate (lr=0.001)\n",
       "    # optimizer = optim.Adam(..., lr=...)\n",
       "    optimizer = ...\n",
       "\n",
       "    # Convert data to PyTorch tensors (the format PyTorch uses)\n",
       "    X_train_tensor = torch.tensor(X_train_bow, dtype=torch.float32)\n",
       "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1) # Target needs an extra dimension\n",
       "    X_val_tensor = torch.tensor(X_val_bow, dtype=torch.float32)\n",
       "    y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
       "\n",
       "    # --- PyTorch Training Loop ---\n",
       "    num_epochs = 10 # Reduced epochs for quicker demonstration\n",
       "    print(f\"Starting PyTorch training for {num_epochs} epochs...\")\n",
       "    \n",
       "    for epoch in range(num_epochs):\n",
       "        model_pt.train() # Set model to training mode\n",
       "        optimizer.zero_grad() # Reset gradients from previous step\n",
       "        \n",
       "        # TODO: Forward pass - Get model predictions for training data\n",
       "        # outputs = model_pt(X_train_tensor)\n",
       "        outputs = ...\n",
       "        \n",
       "        # TODO: Calculate the loss\n",
       "        # Compare model outputs with true training labels (y_train_tensor)\n",
       "        # loss = criterion(..., ...)\n",
       "        loss = ...\n",
       "        \n",
       "        # TODO: Backward pass - Calculate gradients\n",
       "        # loss. ...\n",
       "        \n",
       "        # TODO: Optimizer step - Update model weights\n",
       "        # optimizer. ...\n",
       "        \n",
       "        # --- Validation check every few epochs (Code provided) ---\n",
       "        if (epoch+1) % 5 == 0:\n",
       "            model_pt.eval() # Set model to evaluation mode\n",
       "            with torch.no_grad(): # Don't calculate gradients during evaluation\n",
       "                val_outputs = model_pt(X_val_tensor)\n",
       "                # Convert probabilities (0-1) to binary predictions (0 or 1) using 0.5 threshold\n",
       "                predictions_pt = (val_outputs > 0.5).float()\n",
       "                \n",
       "                # TODO: Calculate validation accuracy for PyTorch model\n",
       "                # Compare predictions_pt with y_val_tensor\n",
       "                # Hint: (predictions_pt.eq(y_val_tensor).sum() / float(y_val_tensor.shape[0])).item()\n",
       "                accuracy_pt = ...\n",
       "                \n",
       "            print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f}, Val Accuracy: {accuracy_pt:.4f}\")\n",
       "\n",
       "    # --- Final Check & Pass Criterion ---\n",
       "    # Re-calculate final accuracy after training is complete\n",
       "    model_pt.eval()\n",
       "    with torch.no_grad():\n",
       "        val_outputs = model_pt(X_val_tensor)\n",
       "        final_predictions_pt = (val_outputs > 0.5).float()\n",
       "        # TODO: Calculate the final accuracy score again\n",
       "        final_accuracy_pt = ...\n",
       "        \n",
       "    print(f\"\\nFinal PyTorch MLP Validation Accuracy: {final_accuracy_pt:.4f}\")\n",
       "\n",
       "    pass_threshold = 0.70\n",
       "    print(f\"\\n--- Pass Criterion Check (Threshold: {pass_threshold*100}%) ---\")\n",
       "    if final_accuracy_pt >= pass_threshold:\n",
       "        print(f\"PASS: Sentiment analysis accuracy ({final_accuracy_pt:.4f}) meets the threshold.\")\n",
       "    else:\n",
       "        print(f\"FAIL: Accuracy ({final_accuracy_pt:.4f}) is below the threshold. Consider model tuning or feature changes.\")\n",
       "else:\n",
       "    print(\"Skipping Challenge 1 due to data loading issues.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Data Visualization: Sentiment Distribution\n",
       "\n",
       "Visualizing the data helps understand the distribution. Here, we plot the number of positive and negative reviews in our sample."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Visualization code - Run this after completing the previous cell\n",
       "if 'df_reviews' in locals() and not df_reviews.empty and 'sentiment' in df_reviews.columns:\n",
       "    plt.figure(figsize=(6, 4))\n",
       "    sns.countplot(x='sentiment', data=df_reviews)\n",
       "    plt.title('Distribution of Sentiments in Sample (0=Negative, 1=Positive)')\n",
       "    plt.xlabel('Sentiment Label')\n",
       "    plt.ylabel('Number of Reviews')\n",
       "    # Add text labels for counts\n",
       "    ax = plt.gca()\n",
       "    # Check if axes has containers before trying to label them\n",
       "    if ax.containers:\n",
       "       for container in ax.containers:\n",
       "           ax.bar_label(container)\n",
       "    plt.show()\n",
       "else:\n",
       "    print(\"Cannot create visualization as data or 'sentiment' column is not available.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Tool Comparison: Custom Model vs. Cloud APIs\n",
       "\n",
       "We've built a custom sentiment analysis model. In practice, businesses often have choices:\n",
       "\n",
       "1.  **Build Custom Models (like we did):**\n",
       "    * **Pros:** Tailored to specific data/needs, potentially higher accuracy on niche topics, full control over the model.\n",
       "    * **Cons:** Requires AI expertise, development time, infrastructure for training and deployment, ongoing maintenance.\n",
       "2.  **Use Pre-built Cloud AI Services:** Services like **Google Cloud Natural Language API**, **Azure Text Analytics**, or **AWS Comprehend** offer ready-to-use sentiment analysis.\n",
       "    * **Pros:** Easy to integrate (API calls), no AI expertise needed to start, managed infrastructure, often cost-effective for standard tasks.\n",
       "    * **Cons:** Less customizable, may not perform as well on highly specific jargon or contexts, potential data privacy concerns (sending data to cloud provider).\n",
       "\n",
       "**Business Decision:** The choice depends on factors like budget, technical expertise, required accuracy, customization needs, and data sensitivity. A startup might begin with a cloud API for speed, while a large enterprise might build custom models for core business functions."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Learning Challenge / Extension (Optional)\n",
       "\n",
       "* **Improve Accuracy:** Can you improve the model's accuracy above the baseline? Try:\n",
       "    * Using `TfidfVectorizer` instead of `CountVectorizer`.\n",
       "    * Adjusting `max_features` in the vectorizer.\n",
       "    * Changing the MLP architecture (e.g., add more layers, change neuron counts).\n",
       "    * Training for more `num_epochs`.\n",
       "* **Analyze Specific Keywords:** Modify the code to analyze sentiment specifically for reviews mentioning 'service' or 'food'. How does sentiment differ for these topics?"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Challenge 2: Deep Learning – Restaurant Rating Prediction\n",
       "\n",
       "**Business Context:** Imagine you're an analyst for a consulting firm advising restaurants. Predicting a restaurant's star rating based on its features (like price range, cuisine type, review count, neighborhood - *Note: we'll use simulated features here for simplicity*) could help identify key factors driving customer satisfaction or dissatisfaction. This is analogous to how financial institutions predict credit risk based on customer profiles or how e-commerce sites predict product popularity.\n",
       "\n",
       "**Goal:** Build a neural network (specifically, a Multi-Layer Perceptron or MLP) to predict a restaurant's star rating (1 to 5 stars). **Important:** For this exercise, we will use *simulated* feature data instead of loading and processing complex features from the Yelp `business.json` file. This keeps the focus on the deep learning model itself.\n",
       "\n",
       "**Pass Criterion:** The model should achieve a test accuracy of **at least 25%** on the simulated data. Accuracy here means the percentage of times the model predicts the *exact* star rating correctly (1, 2, 3, 4, or 5). \n",
       "*Self-Correction Note:* The original notebook had a pass criterion of 80% for this task using random data, which is unrealistic and likely unachievable without significant overfitting or issues in the setup. Predicting the exact star rating out of 5 classes with random features is difficult. A more realistic baseline expectation is slightly better than random guessing (which is 1/5 = 20%). We set the pass criterion to 25% for this simplified setup.*\n",
       "\n",
       "**Business Implication of Accuracy:** Predicting the exact star rating is challenging. An accuracy of 25-30% on this task might seem low, but it's still better than random chance (20%). In a real business scenario with *real features*, higher accuracy would be expected. Even moderate accuracy can help identify trends (e.g., are features X and Y often associated with low ratings?). Businesses often care less about predicting the *exact* rating and more about understanding the *drivers* behind ratings, which this type of model can help uncover (using techniques like feature importance analysis, not covered in detail here)."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# --- Imports for Challenge 2 ---\n",
       "import numpy as np\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
       "import torch\n",
       "import torch.nn as nn \n",
       "import torch.nn.functional as F\n",
       "import torch.optim as optim\n",
       "import seaborn as sns\n",
       "# --------------------------------\n",
       "\n",
       "# 1. Simulate Feature Data (Code provided)\n",
       "# Instead of loading complex Yelp business data, we generate random numbers.\n",
       "# This lets us focus on the PyTorch model structure.\n",
       "print(\"--- Generating Simulated Feature Data for Rating Prediction ---\")\n",
       "n_samples = 2000\n",
       "n_features = 10 # Simulate 10 features (e.g., price range indicator, review count, etc.)\n",
       "num_classes = 5 # 5 star ratings (0=1 star, 1=2 stars, ..., 4=5 stars)\n",
       "\n",
       "# Generate random features\n",
       "X_features = np.random.rand(n_samples, n_features).astype(np.float32)\n",
       "# Generate random ratings (0 to 4, representing 1 to 5 stars)\n",
       "y_ratings = np.random.randint(0, num_classes, size=(n_samples,))\n",
       "\n",
       "print(f\"Generated {n_samples} samples with {n_features} features each.\")\n",
       "print(f\"Target variable: {num_classes} rating classes (0-4 representing 1-5 stars).\")\n",
       "\n",
       "# 2. Data Split (Code provided)\n",
       "X_train, X_test, y_train, y_test = train_test_split(X_features, y_ratings, test_size=0.3, random_state=42, stratify=y_ratings)\n",
       "print(f\"Training set size: {len(X_train)}\")\n",
       "print(f\"Test set size: {len(X_test)}\")\n",
       "\n",
       "# 3. Define the Rating Prediction Model using PyTorch\n",
       "class RatingMLP(nn.Module):\n",
       "    def __init__(self, input_dim, num_classes):\n",
       "        super(RatingMLP, self).__init__()\n",
       "        # Define layers: Input -> Hidden 1 (32 neurons) -> Hidden 2 (16 neurons) -> Output\n",
       "        \n",
       "        # TODO: Define the first fully connected layer (fc1)\n",
       "        # Input dimension: input_dim, Output dimension: 32\n",
       "        # self.fc1 = nn.Linear(..., ...)\n",
       "        self.fc1 = ...\n",
       "        \n",
       "        # TODO: Define the second fully connected layer (fc2)\n",
       "        # Input dimension: 32, Output dimension: 16\n",
       "        self.fc2 = ...\n",
       "        \n",
       "        # TODO: Define the output layer (fc3)\n",
       "        # Input dimension: 16, Output dimension: num_classes\n",
       "        self.fc3 = ...\n",
       "        \n",
       "    def forward(self, x):\n",
       "        # Define how data flows through the layers\n",
       "        \n",
       "        # TODO: Pass input x through the first layer (fc1) and apply ReLU activation\n",
       "        # Use F.relu(...)\n",
       "        x = ...\n",
       "        \n",
       "        # TODO: Pass the result through the second layer (fc2) and apply ReLU activation\n",
       "        x = ...\n",
       "        \n",
       "        # TODO: Pass the result through the output layer (fc3)\n",
       "        # No activation function here, as CrossEntropyLoss expects raw scores (logits)\n",
       "        x = ...\n",
       "        return x\n",
       "\n",
       "# --- Setup for PyTorch Training ---\n",
       "\n",
       "# TODO: Instantiate the model\n",
       "# Use the RatingMLP class defined above.\n",
       "# Pass input_dim=n_features and num_classes=num_classes\n",
       "model_rating = ...\n",
       "\n",
       "# TODO: Define the Loss Function\n",
       "# Use CrossEntropyLoss for multi-class classification.\n",
       "criterion = ...\n",
       "\n",
       "# TODO: Define the Optimizer\n",
       "# Use Adam optimizer. Pass the model's parameters (model_rating.parameters()) and a learning rate (lr=0.01).\n",
       "optimizer = ...\n",
       "\n",
       "# Convert data to PyTorch Tensors (Code provided)\n",
       "X_train_tensor = torch.tensor(X_train)\n",
       "# Target tensor for CrossEntropyLoss should be Long type\n",
       "y_train_tensor = torch.tensor(y_train, dtype=torch.long) \n",
       "X_test_tensor = torch.tensor(X_test)\n",
       "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
       "\n",
       "# --- Training Loop ---\n",
       "print(\"\\n--- Training the Rating Prediction MLP ---\")\n",
       "num_epochs = 50\n",
       "train_losses = []\n",
       "test_accuracies = []\n",
       "\n",
       "for epoch in range(num_epochs):\n",
       "    model_rating.train() # Set model to training mode\n",
       "    optimizer.zero_grad() # Reset gradients\n",
       "    \n",
       "    # TODO: Forward pass - Get model predictions for the training data\n",
       "    # outputs = model_rating(X_train_tensor)\n",
       "    outputs = ...\n",
       "    \n",
       "    # TODO: Calculate loss\n",
       "    # Compare model outputs with true training labels (y_train_tensor)\n",
       "    # loss = criterion(..., ...)\n",
       "    loss = ...\n",
       "    \n",
       "    # TODO: Backward pass - Calculate gradients\n",
       "    # loss. ...\n",
       "    \n",
       "    # TODO: Optimizer step - Update model weights\n",
       "    # optimizer. ...\n",
       "    \n",
       "    train_losses.append(loss.item())\n",
       "    \n",
       "    # --- Evaluate on test set periodically (Code provided for structure) ---\n",
       "    if (epoch+1) % 10 == 0:\n",
       "        model_rating.eval() # Set model to evaluation mode\n",
       "        with torch.no_grad():\n",
       "            test_outputs = model_rating(X_test_tensor)\n",
       "            \n",
       "            # TODO: Get predicted class labels\n",
       "            # Find the index of the highest score for each sample using torch.max(test_outputs, 1)\n",
       "            # The predictions are the second element returned by torch.max\n",
       "            # _, predicted = torch.max(..., ...)\n",
       "            _, predicted = ...\n",
       "            \n",
       "            # TODO: Calculate accuracy\n",
       "            # Use accuracy_score from sklearn.metrics\n",
       "            # Compare predicted.numpy() with y_test_tensor.numpy()\n",
       "            accuracy = ...\n",
       "            \n",
       "            test_accuracies.append(accuracy)\n",
       "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f}, Test Accuracy: {accuracy:.4f}\")\n",
       "\n",
       "# --- Final Evaluation --- \n",
       "model_rating.eval()\n",
       "with torch.no_grad():\n",
       "    test_outputs = model_rating(X_test_tensor)\n",
       "    # TODO: Get final predictions on the test set (same as in the loop)\n",
       "    _, final_predictions = ...\n",
       "    \n",
       "    # TODO: Calculate final accuracy (same as in the loop)\n",
       "    final_accuracy = ...\n",
       "    \n",
       "    print(f\"\\nFinal Test Accuracy: {final_accuracy:.4f}\")\n",
       "    \n",
       "    # Generate Classification Report (Code provided)\n",
       "    print(\"\\nClassification Report:\")\n",
       "    target_names = [f'{i+1} Star' for i in range(num_classes)] # Map 0-4 back to 1-5 stars\n",
       "    print(classification_report(y_test_tensor.numpy(), final_predictions.numpy(), target_names=target_names))\n",
       "\n",
       "# --- Check Pass Criterion ---\n",
       "pass_threshold = 0.25 # Adjusted threshold for simulated data\n",
       "print(f\"--- Pass Criterion Check (Threshold: {pass_threshold*100}%) ---\")\n",
       "if final_accuracy >= pass_threshold:\n",
       "    print(f\"PASS: Rating prediction accuracy ({final_accuracy:.4f}) meets or exceeds the adjusted threshold for simulated data.\")\n",
       "else:\n",
       "    print(f\"FAIL: Accuracy ({final_accuracy:.4f}) is below the threshold. This is expected with random features, but highlights the importance of relevant data.\")\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Data Visualization: Training Progress & Confusion Matrix\n",
       "\n",
       "Visualizing the training process can show if the model is learning. A confusion matrix helps understand *what kind* of errors the model makes (e.g., confusing 4-star with 5-star ratings)."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Plot training loss and test accuracy - Run after completing the previous cell\n",
       "# Ensure results were stored correctly in train_losses and test_accuracies\n",
       "if 'train_losses' in locals() and train_losses and 'test_accuracies' in locals() and test_accuracies: \n",
       "    fig, ax1 = plt.subplots(figsize=(10, 4))\n",
       "\n",
       "    color = 'tab:red'\n",
       "    ax1.set_xlabel('Epoch')\n",
       "    ax1.set_ylabel('Training Loss', color=color)\n",
       "    ax1.plot(range(1, num_epochs + 1), train_losses, color=color, label='Training Loss')\n",
       "    ax1.tick_params(axis='y', labelcolor=color)\n",
       "\n",
       "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
       "    color = 'tab:blue'\n",
       "    ax2.set_ylabel('Test Accuracy', color=color)  \n",
       "    # Plot accuracy recorded every 10 epochs\n",
       "    epochs_recorded = range(10, num_epochs + 1, 10)\n",
       "    ax2.plot(epochs_recorded, test_accuracies, color=color, marker='o', linestyle='--', label='Test Accuracy')\n",
       "    ax2.tick_params(axis='y', labelcolor=color)\n",
       "    ax2.set_ylim(0, 1.0) # Accuracy is between 0 and 1\n",
       "\n",
       "    fig.tight_layout()  \n",
       "    plt.title('Model Training Progress (Simulated Data)')\n",
       "    # Add legends\n",
       "    lines, labels = ax1.get_legend_handles_labels()\n",
       "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
       "    ax2.legend(lines + lines2, labels + labels2, loc='center right')\n",
       "    plt.show()\n",
       "    \n",
       "    # Plot Confusion Matrix\n",
       "    # Ensure final_predictions and y_test_tensor are available from the previous cell\n",
       "    if 'final_predictions' in locals() and 'y_test_tensor' in locals():\n",
       "        cm = confusion_matrix(y_test_tensor.numpy(), final_predictions.numpy())\n",
       "        plt.figure(figsize=(7, 5))\n",
       "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
       "                    xticklabels=[f'{i+1} Star' for i in range(num_classes)], \n",
       "                    yticklabels=[f'{i+1} Star' for i in range(num_classes)])\n",
       "        plt.xlabel('Predicted Rating')\n",
       "        plt.ylabel('Actual Rating')\n",
       "        plt.title('Confusion Matrix for Rating Prediction (Simulated Data)')\n",
       "        plt.show()\n",
       "    else:\n",
       "        print(\"Could not generate confusion matrix. Ensure final predictions were calculated.\")\n",
       "else:\n",
       "    print(\"Skipping visualization as training results are not available.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Tool Comparison: Custom DL vs. Cloud ML Platforms\n",
       "\n",
       "Building deep learning models requires careful setup (libraries like PyTorch/TensorFlow), training infrastructure (potentially GPUs for large models), and deployment expertise.\n",
       "\n",
       "1.  **Build Custom Models (like we did):**\n",
       "    * **Pros:** Maximum flexibility in model architecture, training process, and feature engineering. Potential for state-of-the-art performance.\n",
       "    * **Cons:** High complexity, requires significant AI/ML expertise, managing compute infrastructure can be costly and time-consuming.\n",
       "2.  **Use Cloud Machine Learning Platforms:** Services like **Google Vertex AI**, **Amazon SageMaker**, or **Azure Machine Learning** provide environments and tools to streamline building, training, and deploying ML models (including deep learning).\n",
       "    * **Pros:** Managed infrastructure (scales automatically), integrated tools for data labeling, experimentation (AutoML), model deployment (APIs), monitoring.\n",
       "    * **Cons:** Can still require ML knowledge (though less infrastructure management), potential vendor lock-in, costs associated with platform usage.\n",
       "\n",
       "**Business Decision:** For complex predictive tasks where custom deep learning models are needed, cloud ML platforms often offer a good balance, reducing the infrastructure burden while still providing control. Simpler predictive tasks might be solvable with less complex techniques or even AutoML features within these platforms."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Learning Challenge / Extension (Optional)\n",
       "\n",
       "* **Experiment with Architecture:** Change the number of hidden layers or neurons in the `RatingMLP`. Does it improve accuracy on this simulated data? (Be wary of overfitting!).\n",
       "* **Tune Hyperparameters:** Adjust the `learning_rate` or try a different `optimizer` (e.g., `optim.SGD`).\n",
       "* **(Advanced): Use Real Features:** If you're comfortable with data processing, try loading the `yelp_academic_dataset_business.json` file. Select relevant features (like `review_count`, `is_open`, maybe categories or attributes after processing), merge them with the reviews/ratings, and retrain the model. You would expect significantly better performance with real data."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Challenge 3: Reinforcement Learning – Restaurant Recommendation Simulation\n",
       "\n",
       "**Business Context:** Recommendation systems are everywhere – Netflix suggesting movies, Amazon recommending products, and Yelp suggesting restaurants. These systems often learn over time which recommendations are most likely to be successful (e.g., lead to a click, purchase, or positive interaction). Reinforcement Learning (RL) is one way to approach this: the system learns by *trial and error*, getting 'rewards' for good recommendations and 'penalties' for bad ones.\n",
       "\n",
       "**Goal:** Simulate a simple recommendation system using a Multi-Armed Bandit (MAB) algorithm, specifically epsilon-greedy. Imagine we have 3 different restaurant recommendations ('arms') we can show to users. Each has a different (unknown to us initially) probability of success (e.g., user clicks on it). The algorithm must learn which recommendation is best by balancing *exploration* (trying different recommendations to learn about them) and *exploitation* (showing the recommendation that seems best so far).\n",
       "\n",
       "**Pass Criterion:** The simulation must achieve an average reward of at least **0.65** over 1000 steps (simulated user interactions) using an exploration rate (epsilon) of 0.1. The average reward represents the overall success rate of the recommendations made by the system.\n",
       "\n",
       "**Business Implication:** The epsilon-greedy strategy balances trying new things (exploration) with sticking to what works (exploitation). A high epsilon means more exploration (faster learning initially, but potentially missing out on rewards from the known best option). A low epsilon means more exploitation (maximizing rewards based on current knowledge, but potentially getting stuck on a sub-optimal option if exploration was insufficient). Businesses need to tune this balance based on their goals – launching a new product might require more exploration than optimizing recommendations for established bestsellers."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# --- Imports for Challenge 3 ---\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "# --------------------------------\n",
       "\n",
       "# --- Multi-Armed Bandit Simulation (Epsilon-Greedy) ---\n",
       "\n",
       "def simulate_bandit(true_probs, epsilon, steps):\n",
       "    \"\"\" Simulates an epsilon-greedy multi-armed bandit.\n",
       "    \n",
       "    Args:\n",
       "        true_probs (list): The actual success probability for each arm (recommendation).\n",
       "        epsilon (float): The probability of exploring (choosing a random arm).\n",
       "        steps (int): The number of simulation steps (user interactions).\n",
       "        \n",
       "    Returns:\n",
       "        tuple: (average_reward, Q_estimates, counts, all_rewards)\n",
       "    \"\"\"\n",
       "    np.random.seed(42) # for reproducibility\n",
       "    num_arms = len(true_probs)\n",
       "    \n",
       "    # Initialize: Start with no estimates or counts \n",
       "    Q_estimates = np.zeros(num_arms) # Estimated value (average reward) for each arm\n",
       "    counts = np.zeros(num_arms)      # How many times each arm has been pulled\n",
       "    \n",
       "    all_rewards = [] # Keep track of reward at each step\n",
       "    \n",
       "    print(f\"Starting Bandit Simulation: {num_arms} arms, epsilon={epsilon}, steps={steps}\")\n",
       "    print(f\"True probabilities (unknown to the algorithm): {true_probs}\")\n",
       "    \n",
       "    # --- Main Simulation Loop ---\n",
       "    for step in range(steps):\n",
       "        \n",
       "        # --- Exploration vs. Exploitation Decision ---\n",
       "        # Generate a random number between 0 and 1\n",
       "        random_num = np.random.rand()\n",
       "        \n",
       "        if random_num < epsilon:\n",
       "            # Explore: Choose a random arm (recommendation)\n",
       "            # TODO: Choose a random arm index from 0 to num_arms - 1\n",
       "            # Use np.random.choice(...)\n",
       "            chosen_arm = ...\n",
       "        else:\n",
       "            # Exploit: Choose the arm with the highest current estimated value (Q_estimate)\n",
       "            # TODO: Find the index of the maximum value in Q_estimates\n",
       "            # Use np.argmax(...)\n",
       "            # Note: If there are ties, np.argmax returns the first one.\n",
       "            chosen_arm = ...\n",
       "            \n",
       "        # --- Simulate Pulling the Arm & Getting Reward ---\n",
       "        # Simulate if the user 'clicks' based on the true probability of the chosen arm\n",
       "        # Generate another random number.\n",
       "        # TODO: Get the true probability for the chosen_arm from the true_probs list\n",
       "        prob_success = ...\n",
       "        \n",
       "        # TODO: Determine the reward. Reward is 1 if random number < prob_success, else 0.\n",
       "        # Use an if/else statement or comparison.\n",
       "        reward = ...\n",
       "            \n",
       "        all_rewards.append(reward)\n",
       "        \n",
       "        # --- Update Estimates for the Chosen Arm ---\n",
       "        # TODO: Increment the count for the chosen_arm\n",
       "        # counts[...] += ...\n",
       "        counts[chosen_arm] += ... \n",
       "        \n",
       "        # TODO: Update the Q_estimate for the chosen_arm using the incremental average formula:\n",
       "        # NewEstimate = OldEstimate + (Reward - OldEstimate) / Count\n",
       "        # Q_estimates[...] = Q_estimates[...] + (... - ...) / counts[...]\n",
       "        Q_estimates[chosen_arm] = ...\n",
       "    \n",
       "    # --- Simulation Complete --- \n",
       "    # Calculate the overall average reward (Code provided)\n",
       "    average_reward = np.mean(all_rewards) if all_rewards else 0\n",
       "    print(\"\\nSimulation Complete.\")\n",
       "    return average_reward, Q_estimates, counts, all_rewards\n",
       "\n",
       "# --- Simulation Parameters ---\n",
       "TRUE_PROBS = [0.2, 0.5, 0.7] # Define true success probabilities (unknown to algorithm)\n",
       "EPSILON = 0.1 # Exploration rate (10% chance to explore)\n",
       "N_STEPS = 1000 # Number of simulated user interactions\n",
       "# ---------------------------\n",
       "\n",
       "# --- Run the simulation --- \n",
       "# Call the function you completed above\n",
       "avg_reward, final_Q_estimates, final_counts, rewards_over_time = simulate_bandit(\n",
       "    true_probs=TRUE_PROBS, \n",
       "    epsilon=EPSILON, \n",
       "    steps=N_STEPS\n",
       ")\n",
       "\n",
       "print(f\"\\n--- Results ---\")\n",
       "print(f\"Average Reward over {N_STEPS} steps: {avg_reward:.4f}\")\n",
       "print(f\"Final Estimated Q-values (Success Rates): {final_Q_estimates}\")\n",
       "print(f\"Number of times each arm was chosen: {final_counts}\")\n",
       "\n",
       "# --- Check Pass Criterion ---\n",
       "pass_threshold = 0.65\n",
       "print(f\"\\n--- Pass Criterion Check (Threshold: {pass_threshold}) ---\")\n",
       "if avg_reward >= pass_threshold:\n",
       "    print(f\"PASS: Average reward ({avg_reward:.4f}) meets or exceeds the threshold.\")\n",
       "    print(\"The algorithm successfully learned to favor the better recommendations.\")\n",
       "else:\n",
       "    print(f\"FAIL: Average reward ({avg_reward:.4f}) is below the threshold. Check simulation parameters or logic.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Data Visualization: Learning Progress and Arm Selection\n",
       "\n",
       "Visualizing the average reward over time shows if the agent is learning to make better recommendations. Plotting how often each arm (recommendation) was chosen shows the exploration/exploitation balance in action."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Visualization code - Run this after completing the previous cell\n",
       "# Ensure results are available in rewards_over_time and final_counts\n",
       "if 'rewards_over_time' in locals() and rewards_over_time and 'final_counts' in locals() and final_counts is not None:\n",
       "    # Calculate cumulative average reward\n",
       "    cumulative_avg_reward = np.cumsum(rewards_over_time) / (np.arange(N_STEPS) + 1)\n",
       "\n",
       "    # Plot 1: Average Reward Over Time\n",
       "    plt.figure(figsize=(10, 4))\n",
       "    plt.plot(cumulative_avg_reward)\n",
       "    plt.title('Average Reward Over Time (Epsilon-Greedy)')\n",
       "    plt.xlabel('Steps (User Interactions)')\n",
       "    plt.ylabel('Cumulative Average Reward')\n",
       "    plt.grid(True)\n",
       "    # Draw a line for the best possible average reward (if known)\n",
       "    plt.axhline(y=max(TRUE_PROBS), color='r', linestyle='--', label=f'Max Possible Avg Reward ({max(TRUE_PROBS)})')\n",
       "    plt.legend()\n",
       "    plt.ylim(0, 1.0) # Rewards are between 0 and 1\n",
       "    plt.show()\n",
       "\n",
       "    # Plot 2: Arm Selection Counts\n",
       "    plt.figure(figsize=(7, 5))\n",
       "    arm_indices = np.arange(len(TRUE_PROBS))\n",
       "    plt.bar(arm_indices, final_counts, tick_label=[f'Arm {i}' for i in arm_indices])\n",
       "    plt.title('Total Times Each Arm (Recommendation) Was Chosen')\n",
       "    plt.xlabel('Arm Index')\n",
       "    plt.ylabel('Number of Times Chosen')\n",
       "    # Add text labels for counts\n",
       "    ax = plt.gca()\n",
       "    if ax.containers:\n",
       "        for container in ax.containers:\n",
       "            ax.bar_label(container)\n",
       "    plt.show()\n",
       "else:\n",
       "    print(\"Skipping visualization as simulation results are not available.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Tool Comparison: Simple Bandits vs. Advanced Recommender Systems\n",
       "\n",
       "Multi-Armed Bandits are a simple form of RL useful for optimizing discrete choices (like which ad or headline to show).\n",
       "\n",
       "1.  **Simple Bandits (like we simulated):**\n",
       "    * **Pros:** Relatively simple to understand and implement, effective for problems with a small number of choices, adapts quickly.\n",
       "    * **Cons:** Doesn't typically use user or item features (contextual bandits are an extension that do), less effective when the number of choices is huge.\n",
       "2.  **Advanced Recommender Systems:** Techniques like **Collaborative Filtering** (using user-item interactions), **Content-Based Filtering** (using item features), and **Deep Learning-based models** (e.g., using embeddings) are common in large-scale systems (Netflix, Amazon).\n",
       "    * **Pros:** Can model complex user preferences, scale to millions of items/users, leverage rich feature information for personalization.\n",
       "    * **Cons:** Much more complex to build and maintain, require significant data and computational resources, can suffer from cold-start problems (new users/items).\n",
       "3.  **Cloud Recommendation Services:** Platforms like **AWS Personalize**, **Google Recommendations AI**, or **Azure Personalizer** offer managed services for building sophisticated recommender systems.\n",
       "    * **Pros:** Leverage state-of-the-art algorithms without deep ML expertise, managed infrastructure, faster deployment.\n",
       "    * **Cons:** Cost, less control/customization than building from scratch, data integration effort.\n",
       "\n",
       "**Business Decision:** Simple bandits are great for A/B testing alternative web layouts, headlines, or simple promotions. Full-blown recommender systems are core to businesses like streaming services or e-commerce, justifying the investment in advanced techniques or cloud services."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "#### Learning Challenge / Extension (Optional)\n",
       "\n",
       "* **Experiment with Epsilon:** Rerun the simulation with different values of `epsilon` (e.g., 0.01, 0.3, 0.5). How does it affect the average reward and the final arm counts? Plot the average reward curves for different epsilons on the same graph.\n",
       "* **Add More Arms:** Increase the number of arms in `TRUE_PROBS` (e.g., `[0.1, 0.2, 0.8, 0.5, 0.6]`). Does the algorithm still find the best one effectively?\n",
       "* **(Advanced) Implement UCB:** Research and implement another bandit algorithm like Upper Confidence Bound (UCB). Compare its performance (average reward curve) to epsilon-greedy."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Final Reflection and Business Implementation\n",
       "\n",
       "Reflect on the exercises and consider how these AI techniques could be applied in a business context. Please answer the following questions based on your experience with this project:\n",
       "\n",
       "1.  **Sentiment Analysis Implementation:** If you were deploying the sentiment analysis model (Challenge 1) for a small restaurant chain, what would be the key steps and potential challenges? Consider aspects like:\n",
       "    * Where would you get the review data continuously?\n",
       "    * How often would the model need retraining?\n",
       "    * How would the insights (e.g., % positive/negative, common themes in negative reviews) be integrated into business operations (e.g., informing staff training, menu changes)?\n",
       "\n",
       "2.  **Rating Prediction ROI:** How would you start to estimate the potential Return on Investment (ROI) for implementing the rating prediction model (Challenge 2, assuming it used *real* business features)? What specific business metrics could improve if you could accurately predict (or understand the drivers of) future ratings (e.g., customer retention, targeted marketing effectiveness, operational improvements)?\n",
       "\n",
       "3.  **Ethical Considerations:** Discuss the ethical considerations of using AI like this in a business context. For example:\n",
       "    * Could biases in the Yelp data (e.g., certain demographics reviewing more often) lead to biased model outcomes in sentiment analysis or rating prediction?\n",
       "    * What are the implications if a recommendation system (Challenge 3) consistently promotes certain businesses over others? Could this be unfair?\n",
       "    * How should businesses be transparent about using AI to analyze customer feedback?\n",
       "\n",
       "4.  **Build vs. Buy:** Compare the experience of building the simple models in this project to the potential use of pre-built AI services (like cloud APIs for sentiment or recommendation platforms). For a medium-sized business, what are the major trade-offs to consider between building custom AI solutions versus buying off-the-shelf services (think about cost, speed, flexibility, competitive advantage, required expertise)?\n",
       "\n",
       "5.  **Biggest Learning:** What was your single biggest takeaway or learning point from completing these challenges regarding the practical application of AI in business?\n",
       "\n",
       "--- \n",
       "\n",
       "**Submission:** Ensure your notebook runs successfully from start to finish without errors after filling in the `TODO` sections. Save the completed notebook file (`.ipynb`) and submit it."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7" 
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }