{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Business Insights Project - Teacher Version\n",
    "\n",
    "This notebook provides a complete solution for the Yelp Business Insights Project. It integrates NLP, deep learning, and reinforcement learning using the Yelp Open Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract the Yelp dataset\n",
    "!wget -O yelp_dataset.tar.gz \"https://s3.amazonaws.com/yelp-dataset/yelp_dataset_challenge_academic_dataset.tar.gz\"\n",
    "!tar -xzf yelp_dataset.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Exploratory Analysis\n",
    "\n",
    "The following code loads a sample of Yelp reviews and performs basic exploratory analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load a sample from review.json (adjust sample size as needed)\n",
    "reviews = []\n",
    "with open('yelp_academic_dataset_review.json', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 10000:  # sample first 10,000 reviews\n",
    "            break\n",
    "        reviews.append(json.loads(line))\n",
    "        \n",
    "df_reviews = pd.DataFrame(reviews)\n",
    "print(df_reviews.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: NLP – Sentiment Analysis of Yelp Reviews\n",
    "\n",
    "**Goal:** Build a sentiment analysis classifier using Yelp review texts. Label reviews with stars ≥ 4 as positive (1) and the rest as negative (0).  \n",
    "**Pass Criterion:** The model must achieve at least **70% accuracy** on a held-out validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Labeling: star rating ≥ 4 -> positive (1), else negative (0)\n",
    "df_reviews['sentiment'] = (df_reviews['stars'] >= 4).astype(int)\n",
    "texts = df_reviews['text'].tolist()\n",
    "labels = df_reviews['sentiment'].tolist()\n",
    "\n",
    "# Create a bag-of-words representation\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "X = vectorizer.fit_transform(texts).toarray()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the sentiment analysis model using PyTorch\n",
    "class SentimentMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SentimentMLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.net(x))\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = SentimentMLP(input_dim)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        predictions = (val_outputs > 0.5).float()\n",
    "        accuracy = (predictions.eq(y_val_tensor).sum() / float(y_val_tensor.shape[0])).item()\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f}, Val Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Final check for pass criterion\n",
    "if accuracy >= 0.70:\n",
    "    print(\"PASS: Sentiment analysis accuracy meets the threshold.\")\n",
    "else:\n",
    "    print(\"FAIL: Please review your model and preprocessing steps.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: Deep Learning – Restaurant Rating Prediction\n",
    "\n",
    "**Goal:** Build a neural network to predict a restaurant’s star rating using features extracted from the Yelp dataset.  \n",
    "**Pass Criterion:** The model should achieve a test accuracy of **at least 80%**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_features, y_ratings, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Define the rating prediction model using PyTorch\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRatingMLP\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dim, num_classes):\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28msuper\u001b[39m(RatingMLP, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# For demonstration, we simulate a feature matrix and ratings.\n",
    "n_samples = 1000\n",
    "X_features = np.random.rand(n_samples, 5).astype(np.float32)\n",
    "y_ratings = np.random.randint(0, 5, size=(n_samples,))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_ratings, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the rating prediction model using PyTorch\n",
    "class RatingMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(RatingMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "num_classes = 5\n",
    "model_rating = RatingMLP(input_dim=5, num_classes=num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_rating.parameters(), lr=0.01)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Training loop for rating prediction model\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model_rating.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model_rating(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        model_rating.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model_rating(X_test_tensor)\n",
    "            _, predicted = torch.max(test_outputs, 1)\n",
    "            accuracy = (predicted == y_test_tensor).float().mean().item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f}, Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Final check for pass criterion\n",
    "if accuracy >= 0.80:\n",
    "    print(\"PASS: Rating prediction model meets the accuracy threshold.\")\n",
    "else:\n",
    "    print(\"FAIL: Please review your model and feature engineering steps.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: Reinforcement Learning – Restaurant Recommendation Simulation\n",
    "\n",
    "**Goal:** Simulate a restaurant recommendation system using an epsilon-greedy multi-armed bandit.  \n",
    "**Pass Criterion:** The simulation must achieve an average reward of at least **0.65** with epsilon = 0.1 over 1000 steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def simulate_bandit(epsilon, steps=1000):\n",
    "    np.random.seed(42)\n",
    "    # Define true conversion probabilities for 3 recommendations\n",
    "    true_probs = [0.2, 0.5, 0.7]\n",
    "    num_arms = len(true_probs)\n",
    "    \n",
    "    Q_estimates = np.zeros(num_arms)\n",
    "    counts = np.zeros(num_arms)\n",
    "    rewards = []\n",
    "    \n",
    "    for step in range(steps):\n",
    "        if np.random.rand() < epsilon:\n",
    "            chosen_arm = np.random.choice(num_arms)\n",
    "        else:\n",
    "            chosen_arm = np.argmax(Q_estimates)\n",
    "            \n",
    "        reward = 1 if np.random.rand() < true_probs[chosen_arm] else 0\n",
    "        counts[chosen_arm] += 1\n",
    "        Q_estimates[chosen_arm] = Q_estimates[chosen_arm] + (reward - Q_estimates[chosen_arm]) / counts[chosen_arm]\n",
    "        rewards.append(reward)\n",
    "    \n",
    "    average_reward = np.mean(rewards)\n",
    "    return average_reward, Q_estimates, counts\n",
    "\n",
    "avg_reward, Q_estimates, counts = simulate_bandit(epsilon=0.1, steps=1000)\n",
    "print(\"Average Reward:\", avg_reward)\n",
    "print(\"Estimated Q-values:\", Q_estimates)\n",
    "print(\"Counts:\", counts)\n",
    "\n",
    "threshold = 0.65\n",
    "if avg_reward >= threshold:\n",
    "    print(f\"PASS: Average reward of {avg_reward:.3f} meets or exceeds the threshold.\")\n",
    "else:\n",
    "    print(f\"FAIL: Average reward of {avg_reward:.3f} is below the threshold.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Reflection and Submission\n",
    "\n",
    "Reflect on how each approach (NLP, deep learning, reinforcement learning) applies to real business scenarios using Yelp data. Discuss any challenges encountered and potential improvements.  \n",
    "- Ensure the notebook runs from start to finish without errors.  \n",
    "- Submit the completed notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
